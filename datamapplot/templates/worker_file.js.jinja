{# Web Worker code for file-based (non-inline) data mode #}
const parsingWorkerBlob = new Blob([`
  self.onmessage = async function(event) {
    const { encodedData, JSONParse } = event.data;
    
    async function DecompressBytes(bytes) {
      const blob = new Blob([bytes]);
      const decompressedStream = blob.stream().pipeThrough(
        new DecompressionStream("gzip")
      );
      const arr = await new Response(decompressedStream).arrayBuffer()
      return new Uint8Array(arr);
    }
    
    async function decompressFile(filename) {
      try {
        const currentPath = self.location.href;
        const directoryPath = currentPath.substring(0, currentPath.lastIndexOf('/') + 1);
        const originURL = self.location.origin + directoryPath.replace(self.location.origin, '');
        
        const response = await fetch(originURL + filename);
        if (!response.ok) {
          throw new Error(\`HTTP error! status: \${response.status}. Failed to fetch: \${filename}\`);
        }
        const data = await response.arrayBuffer();
        const decompressedData = await DecompressBytes(new Uint8Array(data));
        return decompressedData;
      } catch (error) {
        console.error('Decompression failed:', error);
        throw error;
      }
    }
    
    let processedCount = 0;
    const decodedData = encodedData.map(async (file, i) => {
      const binaryData = await decompressFile(file);
      processedCount += 1;
      self.postMessage({ type: "progress", progress: Math.round(((processedCount) / encodedData.length) * 95) });
      
      if (JSONParse) {
        const parsedData = JSON.parse(new TextDecoder("utf-8").decode(binaryData));
        return { chunkIndex: i, chunkData: parsedData };
      } else {
        return { chunkIndex: i, chunkData: binaryData };
      }
    });
    
    self.postMessage({ type: "data", data: await Promise.all(decodedData) });
  }
`], { type: 'application/javascript' });
